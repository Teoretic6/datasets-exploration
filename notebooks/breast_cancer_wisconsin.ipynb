{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For inline graphics in Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построить диаграмму рассеяния для двух произвольно взятых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breast_cancer_ds = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view target names\n",
    "# 0 - Malignant\n",
    "# 1 - Benign\n",
    "breast_cancer_ds.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can view description of the dataset\n",
    "print(breast_cancer_ds.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take 1 and 6 parameters (radius and compactness)\n",
    "X = breast_cancer_ds.data[:, [0,5]]  # we only take the first two features.\n",
    "y = breast_cancer_ds.target\n",
    "\n",
    "# Clear figure\n",
    "plt.clf()\n",
    "# Draw scatter plot\n",
    "# Red ones are malignant, gray are benign\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "\n",
    "plt.xlabel('Radius (mean)')\n",
    "plt.ylabel('Compactness (mean)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассчитать матрицу ковариации исходного набора данных (X) и для исходного набора, спроецированного на главные компоненты (X_reduced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = breast_cancer_ds.data\n",
    "y = breast_cancer_ds.target\n",
    "\n",
    "# Normalize data\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance is:\n",
    "maximized - if the two vectors are identical\n",
    "0 - if they are orthogonal\n",
    "negative - if they point to opposite directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X covariance matrix\n",
    "# Need to transpose the matrix, because \n",
    "# we need to place observations in columns:\n",
    "\n",
    "# numpy.cov: each row of m represents a variable, \n",
    "#            each column a single observation of all those variables\n",
    "cov_X = np.cov(X.T)\n",
    "cov_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_reduced covariance matrix\n",
    "cov_X_reduced = np.cov(X_reduced.T)\n",
    "cov_X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверить, что главные компоненты ортогональны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking by finding cos of an angle between vectors\n",
    "# Orthoganal = 90 degrees\n",
    "# Cos90 = 0\n",
    "cos_angle = np.dot(X_reduced[:, 0], X_reduced[:, 1]) / np.linalg.norm(X_reduced[:, 0]) / np.linalg.norm(X_reduced[:, 1])\n",
    "\n",
    "if -0.00001 < cos_angle < 0.00001:\n",
    "    print('Main components are orthogonal')\n",
    "else:\n",
    "    print('Main components are NOT orthogonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнить собственные значения матрицы ковариации X со значениями дисперсии главных компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_X)\n",
    "eig_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are almost similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(eig_vals[0])\n",
    "# print(eig_vals[1])\n",
    "# print(np.var(X_reduced[:,0]))\n",
    "# print(np.var(X_reduced[:,1]))\n",
    "\n",
    "print(\"Variance/eigenvalue 1 component, in %\\n{}\".format(\n",
    "                            np.var(X_reduced[:,0])/eig_vals[0]*100))\n",
    "print(\"Variance/eigenvalue 2 component, in %\\n{}\".format(\n",
    "                            np.var(X_reduced[:,1])/eig_vals[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассчитать total variation (след матрицы ковариации) для X и X_reduced.\n",
    "##  Показать, что данный параметр не меняется при проецировании на главные компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trace = np.trace(X)\n",
    "X_reduced_trace = np.trace(X_reduced)\n",
    "X_reduced_trace / X_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_X_trace = np.trace(cov_X)\n",
    "cov_X_reduced_trace = np.trace(cov_X_reduced)\n",
    "\n",
    "print(cov_X_trace)\n",
    "print(cov_X_reduced_trace)\n",
    "\n",
    "cov_X_reduced_trace / cov_X_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that 2 main components are showing only 63% of previous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построить графики % объясненной дисперсии: а) для исходных признаков, б) для главных компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(100 * pca.explained_variance_ratio_[0], 2))\n",
    "print(round(100 * pca.explained_variance_ratio_[1], 2))\n",
    "# cov_X_reduced / trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_X_reduced)\n",
    "eig_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph for our 2 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_X_reduced)\n",
    "tot = sum(eig_vals) # возьмем сумму всех собствееных сзначений\n",
    "\n",
    "# посчитаем сколько каждый состовляет от общего\n",
    "var_exp = [(i / tot) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "plt.xlabel('component')\n",
    "plt.ylabel('var, %')\n",
    "\n",
    "plt.plot(range(0, len(var_exp), 1), var_exp, 'o', range(0, len(var_exp), 1), var_exp, 'k')\n",
    "plt.plot(range(0, len(cum_var_exp), 1), cum_var_exp, 'o', range(0, len(cum_var_exp), 1), cum_var_exp, 'k')\n",
    "\n",
    "myax = plt.gca()\n",
    "for graph_x,graph_y in zip(range(0, len(var_exp), 1), var_exp):\n",
    "    myax.annotate(\"(\" + str(graph_x) + \", \" + str(graph_y) + \")\", xy=(graph_x, graph_y + 2))\n",
    "for graph_x,graph_y in zip(range(0, len(cum_var_exp), 1), cum_var_exp):\n",
    "    myax.annotate(\"(\" + str(graph_x) + \", \" + str(y) + \")\", xy=(graph_x, graph_y + 2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph for initial data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_X)\n",
    "tot = sum(eig_vals) # возьмем сумму всех собствееных сзначений\n",
    "\n",
    "# посчитаем сколько каждый состовляет от общего\n",
    "var_exp = [(i / tot) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "plt.xlabel('component')\n",
    "plt.ylabel('var, %')\n",
    "\n",
    "plt.plot(range(0, len(var_exp), 1), var_exp, 'o', range(0, len(var_exp), 1), var_exp, 'k')\n",
    "plt.plot(range(0, len(cum_var_exp), 1), cum_var_exp, 'o', range(0, len(cum_var_exp), 1), cum_var_exp, 'k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделить выборку на тренировочную и тестовую (90% и 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(X.shape))\n",
    "print(str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучить классификатор на основе метода k ближайших соседей при фиксированном (произвольном) k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educate\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "# Print report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_train = neigh.predict(X_train)\n",
    "\n",
    "# Print report\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценить качество классификации на тренировочной/тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% - точность на исходных данных\n",
    "\n",
    "89% - точность на тренировочных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделать 10-fold кросс-валидацию при фиксированном k, оценить дисперсию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(neigh, X, y, cv=10)\n",
    "print(\"Cross-validated scores: \\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variation of cross-validation results = {}\".format(np.var(scores))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построить графики зависимости точности на тренировочном/тестовом наборе от числа k (с дисперсией) для n-fold кросс-валидации для разных значений n (n = 2, 5, 8, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(neigh, X, y, cv=10)\n",
    "accuracy_score(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for nbr in range(1, 11):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=nbr)\n",
    "    for i in range(10):\n",
    "        if i not in dct:\n",
    "            dct[nbr] = []\n",
    "        pred = cross_val_predict(neigh, X, y, cv=kf)\n",
    "        \n",
    "        res =  accuracy_score(pred, y)\n",
    "        \n",
    "        dct[nbr].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_mean = {i: np.mean(dct[i]) for i in dct}\n",
    "dct_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.var(list(dct_mean.values()))\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_var = {i: np.var(dct[i]) for i in dct}\n",
    "dct_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mean = [dct_mean[i] for i in range(1, 11)];\n",
    "\n",
    "plt.plot(list(dct_mean.keys()), list(dct_mean.values()), 'o', list(dct_mean.keys()), list(dct_mean.values()), 'k')\n",
    "# plt.plot(list(dct_var.keys()), list(dct_var.values()), 'o', list(dct_var.keys()), list(dct_var.values()), 'k')\n",
    "# plt.plot(range(0, len(cum_var_exp), 1), cum_var_exp, 'o', range(0, len(cum_var_exp), 1), cum_var_exp, 'k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделать вывод о сравнительном качестве предсказаний при разных способах оценки точности. Определить наиболее приемлемый диапазон значений k (числа ближайших соседей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начиная с k=5, точность уже значительно не повышается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Осуществить п. 2 не для исходной выборки, а для X_reduced (число главных компонент варьировать, исследовать диапазон k, определенный в п. 2).\n",
    "\n",
    "## Сравнить качество классификации при обучении классификатора по исходному набору/ по главным компонентам. Исследовать качество классификации при вариации числа главных компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_pca_numbers(components=3):\n",
    "    pca = PCA(n_components=components)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.1, random_state=0)\n",
    "    \n",
    "#     neigh = KNeighborsClassifier(n_neighbors=[5, 6, 7, 8, 9, 10])\n",
    "    neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "    neigh.fit(X_train, y_train)\n",
    "#     knn_params = {'knn__n_neighbors': [2, 5, 8, 10]}\n",
    "#     knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))])\n",
    "#     knn_grid = GridSearchCV(knn_pipe, knn_params,\n",
    "#                         cv=5, n_jobs=-1,\n",
    "#                         verbose=False)\n",
    "#     knn_grid.fit(X_test, y_test)\n",
    "    score = accuracy_score(y_test, neigh.predict(X_test))\n",
    "    report = {\n",
    "#         'best_params' : knn_grid.best_params_,\n",
    "#         'best_score on training set' : knn_grid.best_score_,\n",
    "        'accuracy score on test set': score,\n",
    "        'Number of PCs' : components\n",
    "    }\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [2, 3, 5, 7, 9, 14, 20]\n",
    "\n",
    "for i in comps:\n",
    "    print(test_pca_numbers(components=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 соседей, 5 и более главных компонент"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
