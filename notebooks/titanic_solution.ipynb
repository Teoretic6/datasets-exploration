{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/titanic_train.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## <i>Some dataset analysis and exploration</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "<i>What amount of passengers were male and what amount of passangers were female?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "Male - <u>577</u><br>\n",
    "Female - <u>314</u> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "<i>How many passengers were able to survive?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_series = df['Survived'].value_counts()\n",
    "survived_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description of the dataset we can see that:<br>\n",
    "0 = Didn't survive<br>\n",
    "1 = Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_rate = survived_series[1] / (survived_series[0] + survived_series[1])\n",
    "survival_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_percent = round(survival_rate*100, 2)\n",
    "survival_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "There was a <u>38,38%</u> of survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "<i>What was the ratio of the passengers from the first class to all passengers?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_series = df['Pclass'].value_counts()\n",
    "pclass_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class_rate = pclass_series[1] / (pclass_series[1] + pclass_series[2] + pclass_series[3])\n",
    "first_class_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class_percent = round(first_class_rate*100, 2)\n",
    "first_class_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "There was a <u>24,24%</u> of passengers of the first class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "<i>What was the average and median age of the passengers?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_series = df[\"Age\"]\n",
    "round(age_series.mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_series.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ\n",
    "<u>29,7</u> - average age<br>\n",
    "<u>28</u> - median age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5\n",
    "<i>Is there a correlation between a number of brothers/sisters/spouse and a number of parents/children?<br> \n",
    "Count a Pearson's correlation between \"SibSp\" and \"Parch\" variables.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Link to the doc on corr() method in pandas:</b><br>\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html<br>\n",
    "\n",
    "<b>Link to a theory description:</b><br>\n",
    "https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "\n",
    "<b>Some description about which correlation value is significant:</b><br>\n",
    "http://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/correlation/interpret-the-results/\n",
    "\n",
    "Also you can read about Pearson's correlation in book <b>\"ThinkStats2\"</b> (free pdf book) in chapter <b>\"7.5 Pearson's correlation\"</b>.<br>\n",
    "http://greenteapress.com/wp/think-stats-2e/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = df[['SibSp', 'Parch']]\n",
    "correlation_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ответ\n",
    "Correlation value - <u>0.414838</u><br><br>\n",
    "It means that <u>when \"SibSp\" variable is high, the \"Parch\" variable is also tends to be high and vice versa</u>.<br><br>\n",
    "The value 0.414838 says to us that <u>there is a correlation between these variables, but it's not very strong</u><br><br> \n",
    "<i>(it is common to say that there is a strong correlation between variables if the Pearson's correlation is between 0.5 and 1)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.\n",
    "<i>What was the most popular female name on the ship?<br>\n",
    "Extract from the full name of passengers (variable \"Name\") theirs personal names (variable \"First Name\")</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_df = df[df['Sex'] == \"female\"]\n",
    "women_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what womens' prefixes are there in the dataset.<br>\n",
    "It will help us to make a rule by which we will extract personal names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_set(name_str):\n",
    "    name_list = name_str.split(\" \")\n",
    "    # Return only word with a dot\n",
    "    for word in name_list: \n",
    "        if \".\" in word:\n",
    "            return word\n",
    "\n",
    "prefix_array = women_df[\"Name\"].apply(get_prefix_set).unique()\n",
    "prefix_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print some examples of every category of prefixes to formulate the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_series = women_df[\"Name\"]\n",
    "for prefix in prefix_array:\n",
    "    print(\"Prefix = {}\".format(prefix))\n",
    "    # regex=False for using strict search (using python \"in\" operator underneath)\n",
    "    print(names_series[names_series.str.contains(prefix, regex=False)].head(3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now formulate our rule based on examples:\n",
    "- <b>Mrs.</b> - то брать первое, что в скобках<br>\n",
    "- <b>Miss.</b> or <b>Mme.</b> - то брать то, что после Miss or Mme<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_name(name_str, prefix_array):\n",
    "    name_list = name_str.split(\" \")\n",
    "    \n",
    "    for prefix in prefix_array:\n",
    "        if prefix in name_list:\n",
    "            if(prefix == \"Mme.\" or prefix == \"Miss.\" or \n",
    "               prefix == \"Ms.\" or prefix == \"Mlle.\" or prefix == \"Dr.\"):\n",
    "                return name_list[name_list.index(prefix) + 1]\n",
    "            elif prefix == \"Mrs.\" or prefix == \"Lady.\" or prefix == \"Countess.\":\n",
    "                if name_str.find(\"(\") != -1:\n",
    "                    name = name_str[name_str.index(\"(\")+1:]\n",
    "                    if name.find(\" \") != -1:\n",
    "                        name = name[:name.index(\" \")]\n",
    "                    else:\n",
    "                        name = name[:name.index(\")\")]\n",
    "                    return name\n",
    "                else:\n",
    "                    return name_list[name_list.index(prefix) + 1]\n",
    "\n",
    "names_list = women_df[\"Name\"].apply(get_first_name, args=(prefix_array,)).tolist()\n",
    "names_list[:10] # show 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(names_list).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NAMES = 10\n",
    "\n",
    "top = Counter(names_list).most_common(N_NAMES)\n",
    "top_names = [i[0] for i in top]\n",
    "top_values = [i[1] for i in top]\n",
    "\n",
    "plt.xticks(range(N_NAMES), top_names, rotation='vertical')\n",
    "plt.scatter(range(N_NAMES), top_values)\n",
    "for i in range(N_NAMES):\n",
    "    plt.annotate(top_values[i], xy=(i,top_values[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "<b>Anna</b> was the most popular name on the ship<br>\n",
    "<i>(of course if we assume Mary and Marie as different names :) )</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.\n",
    "## Features extraction and basic DecisionTreeСlassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1\n",
    "<i>There are a missing values in data - for example, for certain passengers age is missing.<br>\n",
    "Drop all samples which contain nan values in any of these variables - 'Pclass', 'Fare', 'Age', 'Sex'\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True, subset=['Pclass', 'Fare', 'Age', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "<i>Leave in dataset only 4 variables:<br> \n",
    "- a passenger's class (Pclass)\n",
    "- price of a ticket (Fare)\n",
    "- a passenger's age (Age)\n",
    "- a passenger's sex (Sex) \n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['Pclass', 'Fare', 'Age', 'Sex']].copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "<i>Convert \"Sex\" variable from string to integer type</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Sex'] = np.where(df2['Sex'] == 'male', 1, 0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4\n",
    "<i>Select the target variable — \"Survived\"</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = df['Survived']\n",
    "target_variable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 \n",
    "<i>Let's for example teach a basic decision tree with random_state=241 and all other arguments as default<i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Link to \"Understanding the decision tree structure\":</b><br>\n",
    "http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html<br>\n",
    "<b>\"Desition tree\" in Scikit Learn docs</b><br>\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(random_state=241)\n",
    "estimator.fit(df2, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(target_variable, estimator.predict(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy</b> of our model is <u>98%</u> which is very high.<br>\n",
    "But it's important to understand that we performed testing of our model only on training data.<br> This score doen't tell us how our model works on a new data.<br>\n",
    "<br>\n",
    "Moreover, there is a high risk that our model is <b>overfitted</b> (or <b>overlearned</b>) which means that it corresponds too closely or exactly to our initial dataset.<br>\n",
    "<br>\n",
    "In the next part we will:\n",
    "- <b>split our training set</b> into separate test and training datasets  \n",
    "- perform <b>feature selection</b>, which will help us to reduce amount of variables by which we will train our model\n",
    "- perform <b>cross validation</b>,  which will help us to more accurately count accuracy of trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "## Applying machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "<i>Find two most important features in dataset.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is called <b>feature selection</b>.<br>\n",
    "Documentation on <b>SelectKBest</b>:<br>\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial df2 shape: {}\".format(df2.shape))\n",
    "print(\"df2: \\n{}\".format(df2.head(10)))\n",
    "\n",
    "# Create and fit selector\n",
    "selector = SelectKBest(k=2)\n",
    "selector.fit(df2, target_variable)\n",
    "\n",
    "# Get ids of columns to keep\n",
    "ids_selected = selector.get_support(indices=True)\n",
    "\n",
    "# Create new dataframe with only desired columns, or overwrite existing\n",
    "df2_reduced = df2.iloc[:,ids_selected]\n",
    "\n",
    "print(\"New df2 shape: \" + str(df2_reduced.shape))\n",
    "df2_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_reduced.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "<b>'Pclass' и 'Sex'</b> - two most important features based on method <b>SelectKBest</b> and statistics test <b>k-classif</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "<i>Train a model using two main features which predicts, will a person survive a Titanic sinking or not.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will <b>divide</b> our reduced dataframe df2_reduced (dataframe with only 2 main features) <b>into test and train datasets</b> in proportion, for example 70-30%.\n",
    "\n",
    "Also let's make an <b>explicit random_state = 241</b> for sake of definite reproduction of results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_rand_state = 241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2_reduced, target_variable, \n",
    "                                                    test_size=0.3, random_state=my_rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train <b>DecisionTreeClassifier</b> with random_state=241 once again, but this time using reduced dataset and testing its accuracy on testing dataset (which wasn't used in training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(random_state=my_rand_state)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, estimator.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>80,4%</u> - not a perfect result, but it's more representative than 98%, which we got using training data as a test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "<i>Train a model using «KNearestNeighbors» and «LogisticRegression»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Scikit-learn KNearestNeighbors:</b><br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html<br>\n",
    "<b>KNearestNeighbors in details:</b><br>\n",
    "http://scikit-learn.org/stable/modules/neighbors.html<br>\n",
    "<b>Scikit-learn LogisticRegression:</b><br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>KNearestNeighbours</b> with amount of neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educate\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LogisticRegression</b> with default parameters (L2 as a penalty; liblinear as a solver because it is recommended for small datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educate\n",
    "regr = LogisticRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4\n",
    "Check the accuracy of models with <b>cross validation</b>.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_neigh = cross_val_score(neigh, df2_reduced, target_variable, cv=5)\n",
    "print(\"Cross-validated scores for each step: \\n{}\".format(scores_neigh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_regr = cross_val_score(regr, df2_reduced, target_variable, cv=5)\n",
    "print(\"Cross-validated scores for each step: \\n{}\".format(scores_regr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5\n",
    "<i>Compare accuracy of «KNearestNeighbors» and «LogisticRegression» in percents.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>«KNearestNeighbors» accuracy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_neigh.mean(), scores_neigh.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>«LogisticRegression» accuracy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_regr.mean(), scores_regr.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "<b>«KNearestNeighbors» with amount of neighbors = 5</b> gives a 2% more accuracy using k=5 cross validation than a <b>«LogisticRegression»</b>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
