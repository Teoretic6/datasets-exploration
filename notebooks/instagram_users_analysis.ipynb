{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import operator\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0: Data preparation (skip it if you want to see a completed task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform data from json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial load of json file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inst_df = pd.read_json('../datasets/instagram_followers.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how data looks like and how many rows we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_count = len(inst_df)\n",
    "inst_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df.dtypes # types of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore this dataset column by column.\n",
    "### And also make all necessary transformations to our dataframe by the way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we have not NaNs in \"audience\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Audience NaNs = \" + str(inst_df['audience'].isnull().sum()))\n",
    "print(\"Rows count = \" + str(rows_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have only 24 people in our dataset with audience field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how not NaN audience looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audience_series = inst_df['audience'].dropna()\n",
    "audience_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can use \"id_deleted\" column to indicate if an account is fake?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows count = \" + str(rows_count))\n",
    "Counter(inst_df['is_deleted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it seems that we have only active users. <br><br>\n",
    "We can get rid of this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'is_deleted' in inst_df.columns:\n",
    "    del inst_df['is_deleted']\n",
    "inst_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see, how many people in our dataset have not empty followers field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_with_followers = inst_df[inst_df['follows'].str.len() != 0]\n",
    "len(people_with_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_with_followers.head(1)['follows'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So followers are represented as list of dictionaries with each follower in list represented as \n",
    "1. datetime (maybe datetime of the beginning of following)\n",
    "2. uid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change \"$date\" field from string to datetime for better future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_format = '%Y-%m-%dT%H:%M:%S.000Z'\n",
    "\n",
    "for row in people_with_followers['follows']:\n",
    "    for follower in row:\n",
    "        if type(follower['t']['$date']) == str:\n",
    "            follower['t'] = datetime.strptime(follower['t']['$date'], dt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df['follows'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how hashtags look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df.head(1)['hashtags'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "field 'p' doesn't seem to be very useful, but \"'t': {'$date'}\" and txt are useful <br><br>\n",
    "Let's transform \"hashtags\" field to the form of dictionaries with key as txt and value as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people_with_hashtags = inst_df[inst_df['hashtags'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_hashtags(hashtags_list):\n",
    "    if hashtags_list is not None:\n",
    "        new_list = []\n",
    "        for single_dict in hashtags_list:\n",
    "            if type(single_dict['t']['$date']) == str:\n",
    "                single_dict['t']['$date'] = datetime.strptime(single_dict['t']['$date'], dt_format)\n",
    "            new_list.append({single_dict['txt']: single_dict['t']['$date']})\n",
    "            \n",
    "        return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inst_df['hashtags'] = people_with_hashtags['hashtags'].apply(transform_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df.head(1)['hashtags'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ig_username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of \"ig_username\" is already a string, so we don't need to convert it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inst_df['ig_username'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look how \"likes\" look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df.head(1)['likes'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 fields:\n",
    "1. uid of the liked person\n",
    "2. pid - process id (don't know why it is given) \n",
    "3. datetime - datetime of the like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_uid_list = []\n",
    "for i in inst_df.head(1)['likes'][0]:\n",
    "    likes_uid_list.append(i['uid'])\n",
    "\n",
    "counter = Counter(likes_uid_list)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people_with_likes = inst_df[inst_df['likes'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_likes(likes_list):\n",
    "    if likes_list is not None:\n",
    "        new_list = []\n",
    "        for single_dict in likes_list:\n",
    "            if type(single_dict['t']['$date']) == str:\n",
    "                single_dict['t'] = datetime.strptime(single_dict['t']['$date'], dt_format)\n",
    "            new_list.append(single_dict)\n",
    "        return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inst_df['likes'] = people_with_likes['likes'].apply(transform_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df['likes'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we transformed 't' field to datetime for future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df['mentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people_with_mentions = inst_df[inst_df['mentions'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_mentions(mentions_list):\n",
    "    if mentions_list is not None:\n",
    "        new_list = []\n",
    "        for single_dict in mentions_list:\n",
    "            if type(single_dict['t']['$date']) == str:\n",
    "                single_dict['t'] = datetime.strptime(single_dict['t']['$date'], dt_format)\n",
    "            new_list.append(single_dict)\n",
    "        return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inst_df['mentions'] = people_with_mentions['mentions'].apply(transform_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df['mentions'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we alse transformed 't' field to datetime for future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update_time and time_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_to_date(x):\n",
    "    x = datetime.strptime(x['$date'], dt_format)\n",
    "    return x\n",
    "\n",
    "inst_df['update_time'] = inst_df['update_time'].apply(dict_to_date)\n",
    "inst_df['time_add'] = inst_df['time_add'].apply(dict_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: the most popular name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name_list = [x['full_name'] for x in inst_df['user']]\n",
    "full_name_list = list(filter(None, full_name_list))\n",
    "full_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = []\n",
    "for name in full_name_list:\n",
    "    # Remove non-ascii characters\n",
    "    name = name.encode('ascii', errors='ignore').decode('ascii')\n",
    "    \n",
    "    name = name.strip()\n",
    "    if name == '':\n",
    "        continue\n",
    "    \n",
    "    if len(name) >= 4 and name[0].isalnum() == True and \\\n",
    "       name[1] == ' ' and \\\n",
    "       name[2].isalnum() == True and \\\n",
    "       name[3] == ' ':\n",
    "        name = name.replace(' ', '')\n",
    "    \n",
    "    new_names.append(name)\n",
    "\n",
    "new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "\n",
    "for name in new_names:\n",
    "    for word in name.split():\n",
    "        if word.lower() in count:\n",
    "            count[word.lower()] += 1\n",
    "        else:\n",
    "            count[word.lower()] = 1\n",
    "            \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_count = sorted(count.items(), key=operator.itemgetter(1))\n",
    "sorted_count.reverse()\n",
    "sorted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing top of the counted names we can see that we are not entirely correct with our estimates - we haven't excluded pronouns, articles and single letters\n",
    "### So to remove all of them we need an external resource of names\n",
    "\n",
    "The first I found was:\n",
    "http://deron.meranda.us/data/census-derived-all-first.txt\n",
    "\n",
    "Let's load it and then filter our counted names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"census-derived-all-first.txt\") as f:\n",
    "    reader = csv.reader(f, delimiter=' ')\n",
    "    d = list(reader)\n",
    "    # Remove everything but names\n",
    "    list_of_names = []\n",
    "    for i in d:\n",
    "        list_of_names.append(i[0].lower())\n",
    "\n",
    "list_of_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_to_remove = []\n",
    "for name_count in sorted_count:\n",
    "    if name_count[0] not in list_of_names:\n",
    "        names_to_remove.append(name_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in names_to_remove:\n",
    "    sorted_count.remove(i)\n",
    "\n",
    "sorted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's insure that there's actually names \"my\" and \"in\" in the list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_names.index('my'))\n",
    "print(list_of_names.index('in'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can paint a graphic that shows, for example, top 10 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = sorted_count[:10]\n",
    "top_ten_names = [i[0] for i in top_ten]\n",
    "top_ten_values = [i[1] for i in top_ten]\n",
    "\n",
    "plt.xticks(range(10), top_ten_names, rotation='vertical')\n",
    "plt.scatter(range(10), top_ten_values)\n",
    "for i in range(10):\n",
    "    plt.annotate(top_ten_values[i], xy=(i,top_ten_values[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Result: \"nicole\" - the most popular name (after \"queen\" and \"love\" which could be used not in term of name)</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Country analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Определить город и страну каждого пользователя по имеющимся данным</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a complex task, because in this dataset we almost have no geodata - data, which is connected to certain geolocation.\n",
    "\n",
    "<i>I said almost because we actually have an \"audience\" attribute, but it is not NaN for just 24 people in this dataset. Of course, it's not enough to put beside every person in this dataset their country.</i>\n",
    "\n",
    "So we need multiple criterias with different weights to categorize users by their country.\n",
    "\n",
    "<b>Here is my suggestions on the criterias which can be used:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is my suggestions on the criterias which can be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Audience field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's watch at the example of not NaN audience field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audience_series[111]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have very interesting stats about the audience:\n",
    " 1. Percent of audience by gender\n",
    " 2. Percent of audience by country\n",
    "\n",
    "And we can put it to good use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggestion 1: If a person have a sugnificant percent of audience (let's say more than 50%) in one country, then it's very likely that he/she is lives in this particular country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \"about\" field in \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at \"user\" field of the first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_df['user'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 'about' we clearly see \"Toronto\" which is a Canada city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggestion 2: Parse 'about' field and find there country names and city names of the person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \"connected_fb_page\" field in \"user\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this field isn't empty, we can connect to the facebook page of the person and find country name there, if it is specified\n",
    "#### Suggestion 3: Parse connected facebook page of the person and find country name there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \"connected_fb_page\" and \"about\" field of the \"mentions\" field and \"likes\" field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take another, more clever strategy of finding a person's country. <br>\n",
    "I'm not certain, what \"mention\" means (since I'm not using Instagram), so I will assume that it is a mention of some other person\n",
    "\n",
    "#### Suggestion 4: Parse connected facebook page of mentioned and liked people of the person (since we have uids of them) and find country name there. \n",
    "#### For example, if there are more than 50% of them from one certain country, then we can suggest that the person who mentioned and liked them is also from this country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Timezone based on datetime, when \"likes\" and \"posts\" are made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last and the most unlikely to work correctly suggestion, it needs further investigation in whether it will work or not.<br><br>\n",
    "Althought itself this method is useless since ideally from this method we can get only timezone of the person but not the country in this timezone. Nevertheless if it is used with other methods, it can confirm or reject country suggestions, which was given by other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggestion 5: Since we have datetime of likes, mentions and posts in UTC, we can try to define timezone of the person (based on when he/she does liked, mentions and posts) to confirm or reject coutries, given by other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 and 4 Classification of users to real and fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Часть​ ​ предоставленных​ ​ пользователей​ ​ – ​ ​ фейковые​ ​ (созданные​ ​ с ​ ​ целью​ ​ накрутки​ ​ активности).\n",
    "Найдите​ ​ признаки​ ​ (или​ ​ создайте​ ​ новые​ ​ на​ ​ основе​ ​ имеющихся),​ ​ по​ ​ которым​ ​ можно​ ​ отличить\n",
    "фейковых​ ​\n",
    "пользователей​ ​ от​ ​ настоящих​ ​ и ​ ​ обоснуйте​ ​ причины​ ​ их​ ​ выбора.\n",
    "4. С​ ​ помощью​ ​ методов​ ​ машинного​ ​ обучения​ ​ (из​ ​ пакета​ ​ scikit-learn)​ ​ реализуйте​ ​ модель,​ ​\n",
    "способную\n",
    "классифицировать​ ​ аккаунты​ ​ на​ ​ реальные​ ​ и ​ ​ фейковые."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fake and real users' features suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggestion 1: Posts count from time of creation (I suppose it is \"time_add\"). If there's lots of posts from the starting point, it's likely that it is a fake account (need to be used with other metrics, real user also can make lots of posts)\n",
    "#### Suggestion 2: Posts count from time of creation and an average time between posts (fake are those, who post has low time of creation and small average time between posts)\n",
    "#### Suggestion 3: Posts count from time of creation and an average time between likes (fake are those, who post has low time of creation and small average time between likes)\n",
    "\n",
    "### All of these suggestions are similar, so further investigation is needed to find another metrics for classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply machine learning for classification of fake and real users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a model with not labeled data (since in our dataset we don't have labels near each account whether it's fake or not) is called unsupervised learning (рус. \"обучение без учителя\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how to apply machine learning to this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cluster analysis</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given \"fake and real users' features suggestions\" we can make a cluster analysis of data based on those features. <br>\n",
    "<br>\n",
    "We should have 2 clusters - real and fake users.\n",
    "<br>\n",
    "<br>\n",
    "Taking some cluster algorithm, such as:\n",
    "1. Prototype-based clustering (for example, k-means)\n",
    "2. Agglomerative hierarchical clustering (for example, with single/complete/average linkage)\n",
    "3. Density-based clustering (for example, DBSCAN)\n",
    "4. Graph-based clustering (for example, spectral clustering)\n",
    "\n",
    "we can check, if data based on this exact features are really clustering into two different clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying cluster algorithm we can check its correctness by visualizing clusters through scatter plots and performing analysis called \"silhouette analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Those features, which will divide data into 2 clusters (real and fake users), will prove that they can be used for classification of the data.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Unfortunatery, I didn't have enough time to apply some of these method and them perform a classification based on clustering which had the best results.</i>\n",
    "<br>\n",
    "<i>But all of these knowledge I've got from reading a book called \"Python Machine Learning\" and a chapter called \"Working with unlabeled data - Clustering analysis\".</i>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
